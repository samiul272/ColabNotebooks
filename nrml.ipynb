{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nrml.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samiul272/ColabNotebooks/blob/master/nrml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgKGL7BCtke1",
        "colab_type": "code",
        "outputId": "ac6a9cb6-7434-41fa-fe11-261abd823a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!pip install -q tensorflow==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 87.9MB 36.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 31.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 31.4MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkQBM-6MdJ03",
        "colab_type": "code",
        "outputId": "cc13d3cf-c4f8-4e51-e61a-f46fe8a9899f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "import tensorflow as tf\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from tqdm import tnrange\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import seaborn as sns\n",
        "from numpy.linalg import norm\n",
        "import pdb\n",
        "%precision 3\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "print(device_lib.list_local_devices())\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 1375053093535793091\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 8580416851643903713\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            "]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-beta1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F9Axt4RegmY",
        "colab_type": "code",
        "outputId": "a21371c8-eb0b-408e-9451-d477ff52107a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "def dist_mat(P1, P2 = None):\n",
        "    if P2 is not None:\n",
        "        X1 = tf.tile(tf.expand_dims(tf.reduce_sum(P1**2, axis= -1), axis= -1), [1, tf.shape(P2)[0]])\n",
        "        X2 = tf.tile(tf.expand_dims(tf.reduce_sum(P2**2, axis= -1), axis= -1), [1, tf.shape(P1)[0]])\n",
        "        R = P1 @ tf.transpose(P2)\n",
        "        D = X1 + tf.transpose(X2) - 2*R\n",
        "        D = tf.sqrt(D)\n",
        "        return D\n",
        "    else:\n",
        "        X1 = tf.tile(tf.expand_dims(tf.reduce_sum(P1**2, axis= -1), axis= -1), [1, tf.shape(P1)[0]])\n",
        "        R = P1 @ tf.transpose(P1)\n",
        "        D = X1 + tf.transpose(X1) - 2*R\n",
        "        D = tf.sqrt(D)\n",
        "        return D\n",
        "    \n",
        "with tf.Session() as sess:\n",
        "    P1 = tf.random.uniform([4,7])\n",
        "    P2 = tf.random.uniform([4,7])\n",
        "    P = dist_mat(P1, P2)\n",
        "    print(P.eval())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4e39f640fef2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mP1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mP2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6XKxb8WemKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NRML:\n",
        "    def __init__(self, N, K, d):\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.convergence_data = []\n",
        "        self.W = 0\n",
        "        self.Wt = tf.Variable(np.zeros(shape = (d,d), dtype = np.float32))\n",
        "        self.X = tf.placeholder(tf.float32, shape=[N, d])\n",
        "        self.Y = tf.placeholder(tf.float32, shape=[N, d])\n",
        "\n",
        "    def fit(self, X, Y, T = 10, plot_convergence = False):\n",
        "        deltas = []\n",
        "        W = 0\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.initialize_all_variables())\n",
        "            for i in tqdm(range(T)):\n",
        "                sess.run(self.step, {self.X: X, self.Y: Y})\n",
        "                Wt = self.Wt.eval()\n",
        "                deltas.append(np.mean((Wt - W)**2))\n",
        "                X = X @ Wt\n",
        "                Y = Y @ Wt\n",
        "                W = Wt\n",
        "        self.convergence_data = deltas\n",
        "        self.W = W\n",
        "        return (W, deltas)\n",
        "\n",
        "    def build_model(self):\n",
        "        X = self.X\n",
        "        Y = self.Y      \n",
        "        \n",
        "        H1 = self.__diff(X, Y)/(self.K*self.N)\n",
        "        H2 = self.__diff(Y, X)/(self.K*self.N)\n",
        "        \n",
        "        D = X - Y\n",
        "        H3 = (tf.transpose(D) @ D)/self.N\n",
        "        \n",
        "        H = (H1 + H2 - H3)\n",
        "        e, Wt = tf.linalg.eigh(H)\n",
        "        Wt = tf.reverse(Wt, axis=[-1])\n",
        "        self.step = self.Wt.assign(Wt)\n",
        "        return (X, Y, self.Wt)\n",
        "    \n",
        "    def __diff(self, x, y):\n",
        "        D = dist_mat(y)\n",
        "        I = tf.argsort(D)\n",
        "        y_knn_idx = I[:, 1:self.K+1]\n",
        "        yt = tf.stack([tf.gather(y, i) for i in tf.unstack(y_knn_idx)], 1)\n",
        "        x = tf.expand_dims(x, 0)\n",
        "        d = x - yt\n",
        "        return tf.reduce_sum(tf.transpose(d, perm = [0, 2, 1]) @ d, axis = 0)\n",
        "    \n",
        "    def plot_convergence_curve(self):\n",
        "            data = pd.DataFrame({'Iterations' : range(len(self.convergence_data)), \n",
        "                                 '$\\Delta$' : self.convergence_data})\n",
        "            sns.lineplot(x = 'Iterations', \n",
        "                         y = '$\\Delta$', \n",
        "                         data = data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7DIh4xbfafN",
        "colab_type": "code",
        "outputId": "28ddf720-de47-4260-e556-dc7dd6b81ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "n1 = [np.random.normal(size=(5,), loc = -100.0 + x*10/4.0, scale = 1.0) for x in range(4)]\n",
        "n1 = np.array(n1, dtype = np.float32)\n",
        "n2 = [np.random.normal(size=(5,), loc = -100.0 + x*10/4.0, scale = 1.0) for x in range(4)]\n",
        "n2 = np.array(n2, dtype = np.float32)\n",
        "\n",
        "nrml = NRML(N=4, K=4, d=5)\n",
        "a = nrml.build_model()\n",
        "a = nrml.fit(n1,n2,10)\n",
        "print(nrml.W)\n",
        "# nrml.plot_convergence_curve()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1777fbf0ea5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnrml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNRML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnrml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnrml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-ac09b0b1e069>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, N, K, d)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6CBYwTyIf2d",
        "colab_type": "code",
        "outputId": "c7eb7d3a-490f-4cbd-dc38-7cea4c78966b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGdAZVtKHAdk",
        "colab_type": "code",
        "outputId": "d4f5d723-b7b9-4cc3-f719-888bb92b72e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install pydrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "file_id = '1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.7.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.5)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.11.3)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (1.12.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.4.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.0.3)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (3.1.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0716 17:13:29.253213 140702337783680 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotDownloadableError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotDownloadableError\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d553fbfd29e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdownloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloaded content \"{}\"'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mGetContentString\u001b[0;34m(self, mimetype, encoding, remove_bom)\u001b[0m\n\u001b[1;32m    191\u001b[0m                     \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_bom\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchContent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mFetchContent\u001b[0;34m(self, mimetype, remove_bom)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       raise FileNotDownloadableError(\n\u001b[0;32m--> 265\u001b[0;31m         'No downloadLink/exportLinks for mimetype found in metadata')\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmimetype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'text/plain'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotDownloadableError\u001b[0m: No downloadLink/exportLinks for mimetype found in metadata"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRrQhp43wFyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQKoRlZYFhoe",
        "colab_type": "code",
        "outputId": "926bfc42-791e-47bf-d525-8e8e08eed9de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# !wget https://drive.google.com/open?id=1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn\n",
        "\n",
        "file_id = '1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn'\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "fh = io.BytesIO()\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "feature_model = load_model('facenet_keras.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-72e8594e78c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_media\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdownloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMediaIoBaseDownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'drive_service' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdNCwcY7JHH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\n",
        "\n",
        "def get_files_in_dir(directory):\n",
        "    dirs = []\n",
        "    for path, subdirs, files in os.walk(directory):\n",
        "        for name in files:\n",
        "            dirs.append(os.path.join(path, name))\n",
        "    return dirs\n",
        "    \n",
        "tr_dir = '../NorthEastern_SMILE_dataset/Data/Train/'\n",
        "class_dirs = [tr_dir + j for j in os.listdir(tr_dir)]\n",
        "img_dirs = get_files_in_dir(tr_dir)\n",
        "\n",
        "datagen_x_tr = [np.array(Image.open(img_dirs[np.random.randint(low = 0, high=len(img_dirs)- 2)])) for x in  range(1024)]\n",
        "\n",
        "\n",
        "data_gen_args = dict(featurewise_center=True,\n",
        "                     featurewise_std_normalization=True,\n",
        "                     rotation_range=10,\n",
        "                     rescale=1./255,\n",
        "                     width_shift_range=0.1,\n",
        "                     height_shift_range=0.1,\n",
        "                     horizontal_flip = True,\n",
        "                     vertical_flip = False,\n",
        "                     zoom_range=0.05)\n",
        "\n",
        "idg = IDG(**data_gen_args)\n",
        "idg.fit(datagen_x_tr)\n",
        "\n",
        "image_generator = idg.flow_from_directory(\n",
        "    tr_dir,\n",
        "    target_size=(160, 160),\n",
        "    class_mode='categorical',\n",
        "    seed=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pab6MJSvJMJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def get_files_in_dir(directory):\n",
        "    dirs = []\n",
        "    for path, subdirs, files in os.walk(directory):\n",
        "        for name in files:\n",
        "            dirs.append(os.path.join(path, name))\n",
        "    return dirs\n",
        "\n",
        "def get_image_samples(directory_list, num_samples = 32, img_size = (160,160)):\n",
        "    C = np.random.choice(class_dirs, size=num_samples)\n",
        "    I = [np.random.choice(get_files_in_dir(j)) for j in C]\n",
        "    return np.array([np.array(Image.open(i).resize(img_size)) for i in I])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53U36dQqJPey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "tr_dir = '../NorthEastern_SMILE_dataset/Data/Train/'\n",
        "class_dirs = [tr_dir + j for j in os.listdir(tr_dir)]\n",
        "img_dirs = get_files_in_dir(tr_dir)\n",
        "\n",
        "class TripletSequence(Sequence):\n",
        "\n",
        "    def __init__(self, class_dirs, classes, W, model, batch_size=8, Nt=16, K = 4,):\n",
        "        self.class_dirs, self.classes = class_dirs, classes\n",
        "        self.batch_size, self.Nt, self.K = batch_size, Nt, K\n",
        "        self.W = W\n",
        "        self.model = model\n",
        "\n",
        "    def __len__(self):\n",
        "        return 100\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pairs = []\n",
        "        for i in range(self.batch_size):\n",
        "            x = np.random.choice(class_dirs)\n",
        "            c = list(self.class_dirs)\n",
        "            c.remove(x)\n",
        "            pairs.append(([x], c))\n",
        "        anchors, positives, negatives = [], [], []\n",
        "        for c, cbar in pairs:\n",
        "            anchor_img = get_image_samples(c, num_samples=1)\n",
        "            pos_img = get_image_samples(c, num_samples=self.Nt)\n",
        "            neg_img = get_image_samples(cbar, num_samples=self.Nt)\n",
        "            \n",
        "            inp = np.concatenate([pos_img, neg_img, anchor_img])\n",
        "            out = feature_model.predict(inp)\n",
        "            out = out @ self.W\n",
        "            anchor, pos, neg = out[-1,:], out[:self.Nt,:], out[self.Nt+1:-1,:]\n",
        "            \n",
        "            anchors.append(anchor_img[0])\n",
        "            positives.append(pos_img[np.argmax(norm(pos - anchor,axis=-1, ord=2))])\n",
        "            negatives.append(neg_img[np.argmin(norm(neg - anchor,axis=-1, ord=2))])\n",
        "        return [anchors, positives, negatives]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3iwfxl2JReX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ALPHA = 0.2\n",
        "\n",
        "def triplet_loss(x):\n",
        "    anchor, positive, negative = x\n",
        "\n",
        "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), 1)\n",
        "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), 1)\n",
        "\n",
        "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), ALPHA)\n",
        "    loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), 0)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def build_facenet_model(embedding_network):\n",
        "    \n",
        "    input_shape = embedding_network.input_shape[1:]\n",
        "    positive_sample = Input(shape=input_shape)\n",
        "    negative_sample = Input(shape=input_shape)\n",
        "    anchor_sample = Input(shape=input_shape)\n",
        "\n",
        "\n",
        "    positive_embedding = embedding_network(positive_sample)\n",
        "    negative_embedding = embedding_network(negative_sample)\n",
        "    anchor_embedding = embedding_network(anchor_sample)\n",
        "    \n",
        "    loss = triplet_loss([anchor_embedding, positive_embedding, negative_embedding])\n",
        "    model = Model(inputs=[anchor_sample, positive_sample, negative_sample],\n",
        "                  outputs=loss)\n",
        "    model.compile(loss='mean_absolute_error', optimizer=Adam())\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_facenet_model(feature_model)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unWzZP9xJWZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr = TripletSequence(class_dirs=class_dirs, classes=class_dirs, W = nrml.W, model=feature_model)\n",
        "x = tr.__getitem__(1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}